{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sed_vis\n",
    "import dcase_util\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from trainer import SED\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from encoder import ManyHotEncoder\n",
    "from utils import classes_labels\n",
    "from model import CRNN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['sed.cnn.cnn.conv0.weight', 'sed.cnn.cnn.conv0.bias', 'sed.cnn.cnn.batchnorm0.weight', 'sed.cnn.cnn.batchnorm0.bias', 'sed.cnn.cnn.batchnorm0.running_mean', 'sed.cnn.cnn.batchnorm0.running_var', 'sed.cnn.cnn.batchnorm0.num_batches_tracked', 'sed.cnn.cnn.conv1.weight', 'sed.cnn.cnn.conv1.bias', 'sed.cnn.cnn.batchnorm1.weight', 'sed.cnn.cnn.batchnorm1.bias', 'sed.cnn.cnn.batchnorm1.running_mean', 'sed.cnn.cnn.batchnorm1.running_var', 'sed.cnn.cnn.batchnorm1.num_batches_tracked', 'sed.cnn.cnn.conv2.weight', 'sed.cnn.cnn.conv2.bias', 'sed.cnn.cnn.batchnorm2.weight', 'sed.cnn.cnn.batchnorm2.bias', 'sed.cnn.cnn.batchnorm2.running_mean', 'sed.cnn.cnn.batchnorm2.running_var', 'sed.cnn.cnn.batchnorm2.num_batches_tracked', 'sed.cnn.cnn.conv3.weight', 'sed.cnn.cnn.conv3.bias', 'sed.cnn.cnn.batchnorm3.weight', 'sed.cnn.cnn.batchnorm3.bias', 'sed.cnn.cnn.batchnorm3.running_mean', 'sed.cnn.cnn.batchnorm3.running_var', 'sed.cnn.cnn.batchnorm3.num_batches_tracked', 'sed.cnn.cnn.conv4.weight', 'sed.cnn.cnn.conv4.bias', 'sed.cnn.cnn.batchnorm4.weight', 'sed.cnn.cnn.batchnorm4.bias', 'sed.cnn.cnn.batchnorm4.running_mean', 'sed.cnn.cnn.batchnorm4.running_var', 'sed.cnn.cnn.batchnorm4.num_batches_tracked', 'sed.cnn.cnn.conv5.weight', 'sed.cnn.cnn.conv5.bias', 'sed.cnn.cnn.batchnorm5.weight', 'sed.cnn.cnn.batchnorm5.bias', 'sed.cnn.cnn.batchnorm5.running_mean', 'sed.cnn.cnn.batchnorm5.running_var', 'sed.cnn.cnn.batchnorm5.num_batches_tracked', 'sed.cnn.cnn.conv6.weight', 'sed.cnn.cnn.conv6.bias', 'sed.cnn.cnn.batchnorm6.weight', 'sed.cnn.cnn.batchnorm6.bias', 'sed.cnn.cnn.batchnorm6.running_mean', 'sed.cnn.cnn.batchnorm6.running_var', 'sed.cnn.cnn.batchnorm6.num_batches_tracked', 'sed.rnn.rnn.weight_ih_l0', 'sed.rnn.rnn.weight_hh_l0', 'sed.rnn.rnn.bias_ih_l0', 'sed.rnn.rnn.bias_hh_l0', 'sed.rnn.rnn.weight_ih_l0_reverse', 'sed.rnn.rnn.weight_hh_l0_reverse', 'sed.rnn.rnn.bias_ih_l0_reverse', 'sed.rnn.rnn.bias_hh_l0_reverse', 'sed.rnn.rnn.weight_ih_l1', 'sed.rnn.rnn.weight_hh_l1', 'sed.rnn.rnn.bias_ih_l1', 'sed.rnn.rnn.bias_hh_l1', 'sed.rnn.rnn.weight_ih_l1_reverse', 'sed.rnn.rnn.weight_hh_l1_reverse', 'sed.rnn.rnn.bias_ih_l1_reverse', 'sed.rnn.rnn.bias_hh_l1_reverse', 'sed.dense.weight', 'sed.dense.bias', 'mel_spec.spectrogram.window', 'mel_spec.mel_scale.fb'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../params.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "encoder = ManyHotEncoder(\n",
    "    list(classes_labels.keys()),\n",
    "    audio_len=config[\"data\"][\"audio_max_len\"],\n",
    "    frame_len=config[\"feats\"][\"n_filters\"],\n",
    "    frame_hop=config[\"feats\"][\"hop_length\"],\n",
    "    net_pooling=config[\"data\"][\"net_subsample\"],\n",
    "    fs=config[\"data\"][\"fs\"],\n",
    ")\n",
    "\n",
    "sed = SED(config, encoder=encoder, sed=CRNN(**config[\"net\"]))\n",
    "print(sed.state_dict().keys())\n",
    "\n",
    "path = '../DvcLiveLogger/dvclive_run/checkpoints/epoch=27-step=23352.ckpt'\n",
    "state_dict = torch.load(path)[\"state_dict\"]\n",
    "sed.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>onset</th>\n",
       "      <th>offset</th>\n",
       "      <th>event_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y--dr8rXrv8k_23.000_33.000.wav</td>\n",
       "      <td>1.667</td>\n",
       "      <td>2.657</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y--dr8rXrv8k_23.000_33.000.wav</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.541</td>\n",
       "      <td>Speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y--dr8rXrv8k_23.000_33.000.wav</td>\n",
       "      <td>2.849</td>\n",
       "      <td>3.480</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y--dr8rXrv8k_23.000_33.000.wav</td>\n",
       "      <td>0.692</td>\n",
       "      <td>2.529</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y--dr8rXrv8k_23.000_33.000.wav</td>\n",
       "      <td>4.271</td>\n",
       "      <td>4.558</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Y--dr8rXrv8k_23.000_33.000.wav</td>\n",
       "      <td>4.798</td>\n",
       "      <td>8.528</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Y--dr8rXrv8k_23.000_33.000.wav</td>\n",
       "      <td>3.664</td>\n",
       "      <td>3.991</td>\n",
       "      <td>Cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  onset  offset event_label\n",
       "0  Y--dr8rXrv8k_23.000_33.000.wav  1.667   2.657      Speech\n",
       "1  Y--dr8rXrv8k_23.000_33.000.wav  0.000   0.541      Speech\n",
       "2  Y--dr8rXrv8k_23.000_33.000.wav  2.849   3.480         Cat\n",
       "3  Y--dr8rXrv8k_23.000_33.000.wav  0.692   2.529         Cat\n",
       "4  Y--dr8rXrv8k_23.000_33.000.wav  4.271   4.558         Cat\n",
       "5  Y--dr8rXrv8k_23.000_33.000.wav  4.798   8.528         Cat\n",
       "6  Y--dr8rXrv8k_23.000_33.000.wav  3.664   3.991         Cat"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_df = pd.read_csv(config[\"data\"][\"strong_tsv\"], sep = '\\t')\n",
    "ref_df = ref_df[ref_df['filename'] == 'Y--dr8rXrv8k_23.000_33.000.wav'].reset_index().drop(columns = ['index'])\n",
    "ref_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load audio signal first\n",
    "audio_container = dcase_util.containers.AudioContainer().load(\n",
    "    'tests/data/a001.wav'\n",
    ")\n",
    "\n",
    "# Load event lists\n",
    "reference_event_list = dcase_util.containers.MetaDataContainer().load(\n",
    "    'tests/data/a001.ann'\n",
    ")\n",
    "estimated_event_list = dcase_util.containers.MetaDataContainer().load(\n",
    "    'tests/data/a001_system_output.ann'\n",
    ")\n",
    "\n",
    "event_lists = {\n",
    "    'reference': reference_event_list, \n",
    "    'estimated': estimated_event_list\n",
    "}\n",
    "\n",
    "# Visualize the data\n",
    "vis = sed_vis.visualization.EventListVisualizer(event_lists=event_lists,\n",
    "                                                audio_signal=audio_container.data,\n",
    "                                                sampling_rate=audio_container.fs)\n",
    "vis.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcase2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
